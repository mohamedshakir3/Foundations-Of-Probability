\chapter{Induced Probability Measures}
Recall that a random variable $X$ is a map from the sample space $\Omega$ to the real number line, so $X: \Omega \rightarrow \real$.\\[2ex]
\textbf{Example.} Consider the flip of a coin with $\Omega = \{H,T\}$. Let $X$ be the number of heads observed, then $X(H) = 1$, and $X(T) = 0$.\\[2ex]
\textbf{Another Example.} Consider the result of rolling 2 die, so 
\[\Omega = \{(1,1), (1,2), (1,3), \ldots, (6,5), (6,6)\}\] 
So $|\Omega| = 36$. Then define an $\omega = (x,y) \in \Omega$ as the result of rolling the first die $x$ and the second die $y$, and the random variable $X$ to be $X(\omega) = x + y$. So $X(2,3) = 5$, $X(6,6) = 12$ etc. We can define a different random variable $Y(x,y) = |x-y|$. We can ask questions about probabilities on $Y$, such as what is the probability $Y = 1$? 
\[P(Y = 1) = P(\{\omega: Y(\omega) = 1\}) = P(\{(1,2),(2,1),(2,3),(3,2), \ldots\}) = \frac{10}{36}\]
So $\{\omega: Y(\omega) = 1\} = Y^{-1}(\{1\})$. In otherwords the probability of an event $E$ occuring can be written as 
\[P_Y(E) = P(Y^{-1}(E))\]  
Where $P_Y$ is called the \emph{induced probability measure} by $Y$. We can check that $P_Y$ satisfies all conditions of a probability measure.
\[P_Y(\real) = 1\]
If $E_i$'s are disjoint, then
\[P_Y\left(\bigcup_{i=1}^\infty E_i\right) = \sum_{i=1}^\infty P_Y(E_i)\]
since 
\[Y^{-1}\left(\bigcup_{i=1}^\infty E_i\right) = \bigcup_{i=1}^\infty Y^{-1}(E_i)\]
\noindent
\textbf{Example.} Flip 2 coins and let $X$ be the number of heads observed. 
\[\Omega = \{HH, HT, TH, TT\}\]
and 
\[X(HH) = 2, X(HT) = X(TH) = 1, X(TT) = 0\]
So $X: \Omega \rightarrow \{0,1,2\} \subset \real$. We can define the induced probability measure $P_X$ by
\[P_X(\{0\}) = P(X=0) = P(\{TT\}) = \frac{1}{4}\]
\[P_X(\{1\}) = P(X=1) = P(\{TH, HT\}) = \frac{1}{2}\]
\[P_X(\{1,2\}) = P(X=0 \text{ or } X = 1) = P(\{TH, HT, HH\}) = \frac{3}{4}\]
\[P_X(\{0,2\}) = P(X=0) + P(X = 2) = P(\{TT, HH\}) = \frac{1}{2}\]
\[P_X(\{0,1,2\}) = 1\]
\section{Cumulative Distribution Functions}
We can know look at a more exact definition of c.d.f's. 
\begin{definition}[Cumulative Distribution Functions]
    If $X$ is a random variable $X: \Omega: \real$, then the c.d.f of $X$ is
    \[F_X(x) = P(X \leq x) = P(\{\omega: X(\omega) \leq x\}) = P_X((-\infty, x])\] 
\end{definition}
\subsection{Properties of Cumulative Distribution Functions}
\begin{theorem}
    
    Let $F$ be a c.d.f, then
    \begin{enumerate}[label=(\roman*)]
        \item $F(x) \geq 0$ and $F(x)$ is non-decreasing.
        \item $\lim\limits_{x\rightarrow t^+}F(x) = F(t)$
        \item $F(-\infty) = 0$ and $F(-\infty)= 1$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    \begin{enumerate}[label=(\roman*)]
        \item  To prove $F$ is non-decreasing, we need to show 
        \[F(x + h) - F(x) \geq 0, \ \forall h \geq 0\]
        \[F(x + h) - F(x) = P(x < X \leq x+h) \geq 0\]
        Since probability measures are positive, therefore $F$ is non-decreasing.
        \item Consider 
        \[E_n = (-\infty, x + h_n)\]
        With $h_n \downarrow 0$, for example $h_n = \frac{1}{n} \downarrow 0$.  Then, $E_n$ is decreasing so the limit is 
        \[\lim_{n\rightarrow \infty} E_n = \bigcap_{n=1}^\infty E_n = (-\infty, x]\]
        Thus, from \hyperref[lem:1.5.2]{Lemma 1.5.2}, we have
        \[\lim_{n\rightarrow \infty} P(E_n) = P\left(\lim_{n\rightarrow\infty} E_n\right) = P\left((-\infty, x]\right) = F(x)\]
        Therefore we showed that 
        \[\lim_{n\rightarrow\infty} F(x + h_n) = F(x)\]
        So $F$ is right continuous.
        \item We know $F(N) - F(-N) = P(-N < X \leq N) = P((-N,N])$ for any, $N$, so 
        \[\lim_{N \rightarrow \infty} = (-\infty,\infty) \implies P((-N,N])\uparrow 1\]
        Therefore,
        \[\lim_{N\rightarrow \infty} [F(N) - F(-N)] = 1 \]
        Thus $F(\infty) = 1$ and $F(-\infty) = 0$.
    \end{enumerate}
\end{proof}
\noindent
\textbf{Remark.} A distrbiution function $F$ is continuous at $x \in \real$ if and only if $P(X = x) = 0$, since 
\[P(X=x) = F(x) - \lim_{x \rightarrow x^-}F(x) = \text{The size of the jump at $x$}\]
\begin{definition}
    A random variable $X$ is of continuous type if $F(x) = P(X \leq x)$ is a continuous function. 
\end{definition}
\noindent
\textbf{Example.} Let 
\[F(x) = \frac{1}{2}I(x \in [0,1)) + \frac{2x}{3}I\left(x \in [1, 3/2)\right) + I\left(x \in [3/2, \infty)\right)\]
This c.d.f is not continuous since there is a jump at $x = 0$ and $x = 1$, so we have 
\[P(X = 0) = F(0) - \lim_{x\rightarrow 0^-} F(x) = \frac{1}{2} - 0\]
\[P(X = 1) = \frac{3}{2} - \frac{1}{2} = \frac{1}{6}\]
Recall that a set is called \emph{countable} if we can define a bijection from the natural numbers to the set. For example 
\[f:\nat \mapsto \{2,4,6,8,\ldots\}  \implies f(n) \coloneqq 2n\]
We say a set is at most countable if it is finite or countable. 
\begin{lemma}
    If $F$ is a c.d.f, then the number of discontinuities of $F$ is at most countable.
\end{lemma}
\begin{proof}
    Define 
    \[p(x) \coloneqq F(x) - F(x^-) = P(X = x)\]
    Let $D$ be the set of discontinuities of $F$, so 
    \[D = \{x: p(x) > 0\}\]
    We need to show that $D$ is at most countable. Let 
    \[D_n \coloneqq \left\{x: \frac{1}{n+1} < p(x) \leq \frac{1}{n}\right\}\]
    Then, 
    \[\bigcup_{n=1}^\infty D_n = D\]
    We must prove that $D_n$ is finite. $D_n$ is bounded below by $\frac{1}{n+1}$, so $|D_n|$ is at most $n$, since if we have $n+1$ points, 
    \[P(D_n) > \frac{n+1}{n+1} = 1\]
    which is a contradiction. Therefore, $D$ is at most countable.
\end{proof}
\begin{lemma}
    Let $X$ be a random variable with c.d.f $F$ and $p(x) = F(x) - F(x^-) = P(X=x)$. Let $D = \{x_1,x_2, \ldots\} $ be the set of discontinuities of $F$. Define the step function 
    \[G(x) = \sum_{n=1}^\infty p(x_i)I(x \geq x_i)\]
    Then $H(x) = F(x) - G(x)$ is non-decreasing and continuous on $\real$.
\end{lemma}
\textbf{Note.} We call $G$ a step function since it increases in discrete intervals and is constant in between. \\[2ex]
\begin{proof}
    Obviously $H$ is right continuous since $F(x)$ and $G(x)$ are right continuous. We want to show that $H$ is also left continuous. Not that if $x' < x$, then 
    \[H(x) - H(x') = F(x) - F(x') - G(x) + G(x')\]
    As $x' \uparrow x$, then $F(x) - F(x')$ converges to the size of jummp of $F$ at $x$, and $G(x) - G(x')$ converges to the size of the jump of $G$ at $x$. The size of jump in both cases is $p(x)$ which shows that $H(x) - H(x') \rightarrow 0$ as $x'\uparrow x$. Therefore $H$ is continuous. Now we want to show that $H$ is non-decreasing. Note that
    \[\sum_{x' < x_n \leq x} p(x_n)\leq P(x' < X \leq x) = F(x) - F(x')\]
    We want to show that $H(x) \geq H(x')$.
    \begin{align*}
        H(x') &= F(x') - G(x')\\
        \implies H(x) - H(x') &= F(x) - F(x') - (G(x) - G(x'))\\
        &= F(x) - F(x') - \sum_{x' < x_n \leq x} p(x_n)\\ 
    \end{align*}    
    We know that $\sum\limits_{x' < x_n \leq x} p(x_n) \leq F(x) - F(x')$, therefore $H(x) - H(x') \geq 0$. Thus $H$ is non-decreasing. 
\end{proof}
\begin{theorem}
    Let $F$ be a c.d.f, then there exists two c.d.f's $F_d$, $F_c$ where $F_d$ is a discrete step function and $F_c$ is a continuous function such that
    \[F = \alpha F_d + (1- \alpha)F_c\]
    for some $\alpha \in [0,1]$, and 
    \[F_d = \frac{G(x)}{\alpha}\]
    \[F_c = \frac{H(x)}{1 - \alpha}\]
\end{theorem}
\noindent
\textbf{Example.} Find $F_c$, $F_d$, and $\alpha$ for the following c.d.f
\[F(x) = \frac{1}{2}I(0 \leq x < 1) + \frac{2x}{3}I(1 \leq x < 3/2) + I(x \geq 3/2)\]
\textbf{Solution.} Consider the set of discontinuities of $F$, we have $\{x_1 = 0, x_2 = 1\}$. Then,
\begin{align*}
    p(x_1) &= p(0) = \frac{1}{2}\\
    p(x_2) &= p(1) = \frac{2}{3} - \frac{1}{2} = \frac{1}{6}
\end{align*}
Then we can define $G(x)$, 
\[G(x) = \sum_{x_i \leq x} p(x_i)\]
If $x < 0$, then $G(x) = 0$, similarly 
\[0 \leq x < 1 \implies G(x) = \frac{1}{2}\]
\[1 \leq x \implies G(x) = \frac{1}{2} + \frac{1}{6} = \frac{2}{3}\]
So we can define $G(x)$ with indicator functions 
\[G(x) = \frac{1}{2}I(0 \leq x < 1) + \frac{2}{3}I(1 \leq x)\]
We can see that $G(x)$ is not a c.d.f since $G(\infty) \neq 1$, then our $\alpha$ is 
\[\alpha = G(\infty) = \frac{2}{3} \implies 1 - \alpha = \frac{1}{3}\]
To find $H(x)$, we can write $G(x)$ and $F(x)$ as 
\[F(x) = \begin{cases}
    0 & x < 0\\
    \frac{1}{2} & 0 \leq x < 1\\
    \frac{2x}{3} & 1 \leq x < \frac{3}{2}\\
    1 & x \geq \frac{3}{2}
\end{cases}\]
\[G(x) = \begin{cases}
    0 & x < 0\\
    \frac{1}{2} & 0 \leq x < 1\\
    \frac{2}{3} & 1 \leq x < \frac{3}{2}\\
    \frac{2}{3} & x \geq \frac{3}{2}
\end{cases}\]
Then, 
\[H(x) = F(x) - G(x) = \begin{cases}
    0 & x < 0\\
    0 & 0 \leq x < 1\\
    \frac{2x}{3} - \frac{2}{3} = \frac{2}{3}(x-1) & 1 \leq x < \frac{3}{2}\\
    \frac{1}{3} & x \geq \frac{3}{2}
\end{cases}\]
Now we can find $F_d$ and $F_c$, 
\[F_d(x) = \frac{G(x)}{\alpha} = \frac{3G(x)}{2} = \begin{cases}
    0 & x < 0\\
    \frac{3}{4} & 0 \leq x < 1\\
    1 & x \geq 1
\end{cases}\]
\[F_c(x) = \frac{H(x)}{1 - \alpha} =  3H(x) = \begin{cases}
    0 & x <1\\
    2(x-1) & 1 \leq x < \frac{3}{2}\\
    1 & x \geq \frac{3}{2}
\end{cases}\]
Notice that the p.d.f
\[\frac{dF_d(x)}{dx} = \begin{cases}
    \frac{3}{4} & x = 0\\
    \frac{1}{4} & x = 1
\end{cases}
\]
This is the p.d.f of a Bernoulli random variable with $p = 1/4$, and 
\[\frac{dF_c(x)}{dx} = \begin{cases}
    2 & 1 \leq x < \frac{3}{2}\\
    0 & \text{otherwise}
\end{cases}\]
This is the p.d.f of a uniform random variable on $[1,3/2]$. Therefore, $F$ is a linear combination of a Bernoulli random variable and a uniform random variable. We can calculate the expected value 
\[E(X) = \int xdF(x) = \alpha \int x dF_d(x) + (1-\alpha)\int x dF_c(x)\]
\textbf{Example.} Let $X$ be a random variable with continuous c.d.f $F$. Find the distrbiution for 
\begin{enumerate}[label=(\roman*)]
    \item $U = F(X)$
    \item If $U \sim [0,1]$, then $X \eqd F^{-1}(U)$
    \item Use (i) and (ii) to show that $X = -\ln U$ has an exponentional distrbution. 
\end{enumerate}\
\textbf{Note.} If $U \sim \Unif(0,1)$, then 
\[U \eqd 1 - U\]
since the c.d.f for $1 - U$ is 
\[G(t) = P(1 - U \leq t) = P(U \geq 1 - t) = \int_{1-t}^1 du = t\]
\textbf{Solution.} 
\begin{enumerate}[label=(\roman*)]
    \item We have
    \[G(u) = P(F(X) \leq u) = P(F^{-1}(F(X)) \leq F^{-1}(u)) = F(F^{-1}(u)) = u\]
    Therefore, $g(u) = G'(u) = 1$ for $u \in [0,1]$.
    \item Notice that 
    \begin{align*}
        P(F^{-1}(U) \leq x) &= P(F(F^{-1}(U)) \leq F(s))\\
        &= P(U \leq F(x))\\
        &= \int_0^{F(x)} du = F(x)
    \end{align*}
    \item Now using (i), (ii)
    \begin{align*}
        F(x) &= P(-\ln U \leq x)\\
        &= P(U \geq e^{-x})\\
        &= 1 - P(U \leq e^{-x})\\
        &= 1 - e^{-x}\\
        \implies f(x) &= F'(x) = e^{-x}I(x \geq 0)
    \end{align*}    
\end{enumerate}



\section{Conditional Probability Measure}
\begin{definition}
    Let $P(X \leq x) = F(x)$ be continuous. If there exists a non-negative function $f$ such that 
    \[P(X \leq x) = \int_{-\infty}^x f(t)dt\]
    Then $f$ is called the probability density function (p.d.f). 
\end{definition}

\begin{definition}
    Let $(\Omega, \mathcal{F}, P)$ be a probability space and $B \in \mathcal{F}$ with $P(B) > 0$. The conditional probability measure given $B$ as 
    \[Q_B(A) = P(A|B) = \frac{P(A \cap B)}{P(B)}\]
\end{definition}
\begin{theorem}
    $Q_B$ is a probability measure on $(\Omega, \mathcal{F})$.
\end{theorem}
\begin{proof}
    We can check each property of probability measures
    \begin{enumerate}[label=(\roman*)]
        \item $Q_B(\emptyset) = 0$ since 
        \[Q_B(\emptyset) = \frac{P(\emptyset \cap B)}{P(B)} = \frac{P(\emptyset)}{P(B)}= 0\]
        \item The sum of disjoint sets is
        \begin{align*}
            Q_B\left(\bigcup_{i=1}^\infty A_i\right) &= \frac{P(B \cap (A_1 \cup A_2 \cup \cdots))}{P(B)}\\
            &= \frac{P((B \cap A_1) \cup (B \cap A_2) \cup \cdots)}{P(B)}\\
            &= \sum_{i=1}^\infty \frac{P(B \cap A_i)}{P(B)}\\
            &= \sum_{i=1}^\infty Q_B(A_i)
        \end{align*}
        \item $Q_B(\Omega) = 1$ since
        \[Q_B(\Omega) = \frac{P(\Omega\cap B)}{P(B)} = \frac{P(B)}{P(B)} = 1\]
        \item $P(A \cap B) \leq P(B)$ since $A \cap B \subset B$, therefore $Q_B(A) \in [0,1]$.
    \end{enumerate}
\end{proof}
\textbf{Remark.} We have 
\[P(A^c|B) = 1 - P(A|B)\]
but we this does not apply for $B^c$,
\[P(A|B^c) \neq 1 - P(A|B)\]
\begin{theorem}[Law of Total Probability]
    Let $\{E_i\}$ be a sequence of disjoint events such that 
    \[\Omega = \bigcup_{i=1}^\infty E_i\]
    Then 
    \[P(A) = \sum_{i=1}^\infty P(A | E_i)P(E_i)\]
\end{theorem}
\begin{proof}
    \begin{align*}
        P(A) &= P(A \cap \Omega)\\
        &= P\left(A \cap \bigcup_{i=1}^\infty E_i\right)\\
        &= P\left(\bigcup_{i=1}^\infty A \cap E_i\right)\\
        &= \sum_{i=1}^\infty P(A \cap E_i)\\
        &= \sum_{i=1}^\infty P(A | E_i)P(E_i)
    \end{align*}
\end{proof}
\begin{theorem}[Bayes' Theorem]
    Let $\{E_i\}$ be a sequence of disjoint events such that 
    \[\Omega = \bigcup_{i=1}^\infty E_i\]
    Then 
    \[P(E_i | A) = \frac{P(A|E_i)P(E_i)}{P(A)} = \frac{P(A | E_i)P(E_i)}{\sum_{i=1}^\infty P(A | E_i)P(E_i)}\]
\end{theorem}
\begin{proof}
    
\end{proof}
\textbf{Example.} Roll a die and flip a coin the number of times that appears on the die. Let $X$ denote the random variable of the number of heads observed. What is the distrbiution of $X$? If we observed 3 heads, what is the probability that the die is 4?\\[2ex]
\textbf{Solution.} Let $Y$ denote the number on the die, then 
\begin{align*}
    P(X = k) &= \sum_{i=1}^{6} P(X = k | Y = i)P(Y = i)\\
    &= \sum_{i=1}{i \choose k} \left(\frac{1}{2}\right)^k \left(\frac{1}{2}\right)^{i-k} \frac{1}{6}\\
    &= \frac{1}{6}\sum_{i=1}^6 {i \choose k} \left(\frac{1}{2}\right)^i
\end{align*}
Then, we want to find $P(Y = 4 | X = 3)$, using Bayes' theorem
\begin{align*}
    P(Y = 4 | X = 3) &= \frac{P(X=3|Y=4)P(Y=4)}{P(X=3)}\\
    &= \frac{{4 \choose 3}\left(\frac{1}{2}\right)^k\frac{1}{2}\frac{1}{6}}{\frac{1}{6}\sum_{i=3}^6{i \choose 3}\left(\frac{1}{2}\right)^i}\\
    &= \frac{4}{16}
\end{align*}
\textbf{Example.} An urn contains $m+n$ chips of which $M$ are white and the rest are black. A chip is drawn at random without observing its color, then another chip is drawn. What is the probability that the second chip is white?\\[2ex]
\textbf{Solution.}
Let $E_1$ be the event that the first chip is white and $E_2$ be the event that the first chip is black. Also let $A$ be the event the second chip is black. We have 
\[P(E_1) = \frac{m}{m+n}\]
and 
\[P(A|E_1) = \frac{m-1}{m+n-1}, \ P(A|E_2) = \frac{m}{m+n-1}\]
Then, from the law of total probability, 
\begin{align*}
    P(A) &= P(A|E_1)P(E_1)+ P(A|E_2)P(E_2)\\
    &= \left(\frac{m-1}{m+n-1}\right)\left(\frac{m}{m+n}\right) + \left(\frac{m}{m+n-1}\right)\left(\frac{n}{m+n}\right) \\
    &= \frac{m}{m+n}
\end{align*}